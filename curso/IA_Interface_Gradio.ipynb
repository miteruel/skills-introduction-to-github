{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#borra o comenta esta linea para que no de error\n",
    "#!pip install gradio \n",
    "#!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a036ecc-33b7-4f1a-8230-cd702ea9d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7880\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# funcion recibe 2 parametros de entrada que corresponde a inputs\n",
    "# devuelve un solo resultado para outputs\n",
    "def Saludos(nombre, intensidad):   \n",
    "    return \"hola \" * intensidad + nombre + \"!\"\n",
    "\n",
    "# Crea una interface gradio: \n",
    "# fn: funcion que procesa inputs y devuelve outputs\n",
    "# inputs: controles graficos que corresponden a los datos de entrada\n",
    "# outputs. controlres graficos que muestral el resultado\n",
    "demo = gr.Interface(\n",
    "    fn=Saludos,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"]\n",
    "    # https://www.gradio.app/guides/using-flagging\n",
    "    # ,allow_flagging=\"never\" # \"manual\" (default), \"auto\",  \"never\".\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef99aaa-80c8-42fa-b2d1-2148174048fe",
   "metadata": {},
   "source": [
    "* https://www.gradio.app/\n",
    "* https://www.gradio.app/playground\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23206f-6eb7-42f3-8df1-faf689f56e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98febb82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597f51a-e47c-483b-9397-8e5d062c8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "detec=keras_ocr.detection.Detector(load_from_torch=False)\n",
    "#detec=keras_ocr.detection.Detector(load_from_torch=True)\n",
    "pipeline = keras_ocr.pipeline.Pipeline(detec)\n",
    "\n",
    "\n",
    "def image(im):\n",
    "   images=[im]\n",
    "   prediction_groups = pipeline.recognize(images)\n",
    "  \n",
    "   fig, axs = plt.subplots(nrows=1, figsize=(40, 40))\n",
    "   keras_ocr.tools.drawAnnotations(image=im, predictions=prediction_groups[0], ax=axs)  \n",
    "        \n",
    "   # import FigureCanvasAgg as FigureCanvas\n",
    "   canvas = FigureCanvas(fig)\n",
    "   canvas.draw()\n",
    "   image = np.asarray(canvas.buffer_rgba())\n",
    "    \n",
    "    # Convert to an image using PIL\n",
    "   im = Image.fromarray(image)\n",
    "   # im.show()  # muestra imagen externamente\n",
    "   return im,str(prediction_groups)\n",
    "  \n",
    "     \n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    im = gr.Image()\n",
    "    im2 = gr.Image()\n",
    "    tex=gr.Textbox()\n",
    "    #https://www.gradio.app/docs/gradio/button\n",
    "    btn = gr.Button(value='OCR')\n",
    "    btn.click(lambda x: image(x), outputs=[im2,tex], inputs=im)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n",
    "    #demo.launch(share=True)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da3e363-43d5-4634-a84d-d274f5d67a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "keras.utils.plot_model(detec.model, \"my_first_model.png\")\n",
    "detec.model.summary()\n",
    "pipeline.recognizer.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6270f089-1cde-4fa4-a2d0-9d81a4e05692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loga(s):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6a037-4428-4dc8-b6b1-1105e691373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imasi,PREDICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492319ab-e73e-4d91-8a60-cf1e0e83f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RETORNA)\n",
    "print(RETORNA_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beacfc24-eecc-4ab6-9ef7-ac2c97933da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7882\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "model = \"llama3.1:latest\"  # TODO: update this for whatever model you wish to use\n",
    "\n",
    "\n",
    "\n",
    "def llama_chat_endpoint (messages):\n",
    "    r = requests.post(\n",
    "        \"http://127.0.0.1:11434/api/chat\",\n",
    "        json={\"model\": model, \"messages\": messages, \"stream\": True},\n",
    "    \tstream=True\n",
    "    )   \n",
    "    r.raise_for_status()\n",
    "    return r\n",
    "\n",
    "def slow_echo(message, history):\n",
    "    messages = [{\"role\": \"user\", \"content\": message}]\n",
    "    #messages.append({\"role\": \"user\", \"content\": texto})\n",
    "   \n",
    "    r = llama_chat_endpoint(messages)\n",
    " \n",
    "    output = \"\"\n",
    "\n",
    "    for line in r.iter_lines():\n",
    "       # print(line)\n",
    "        body = json.loads(line)\n",
    "        if \"error\" in body:\n",
    "            raise Exception(body[\"error\"])\n",
    "        if body.get(\"done\") is False:\n",
    "            message = body.get(\"message\", \"\")\n",
    "            content = message.get(\"content\", \"\")\n",
    "            output += content\n",
    "            # the response streams one token at a time, print that as we receive it\n",
    "            yield output\n",
    "           \n",
    "        if body.get(\"done\", False):\n",
    "            message[\"content\"] = output\n",
    "            return message\n",
    "\n",
    "    \n",
    "demo = gr.ChatInterface(slow_echo)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n",
    "    #demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbb336-f93c-4a6f-a570-b606f52de1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25f951e2",
   "metadata": {},
   "source": [
    "\n",
    "https://github.com/clovaai/CRAFT-pytorch\n",
    "https://github.com/clovaai/CRAFT-pytorch/blob/master/craft.py\n",
    "\n",
    "https://arxiv.org/pdf/1904.01941\n",
    "\n",
    "https://www.toolify.ai/es/category/ai-image-segmentation\n",
    "\n",
    "\n",
    "https://github.com/janzd/CRNN\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/transformer?hl=es-419#setup_input_pipeline\n",
    "https://runebook.dev/es/docs/scikit_image/user_guide/tutorial_segmentation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d3ac6-da46-4934-9781-68b590171864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ksj ## quita para no dar error\n",
    "\n",
    "!pip install tensorflow==2.15.0\n",
    "\n",
    "!pip install matplotlib\n",
    "!pip install keras_ocr\n",
    "!pip install pydot\n",
    "!pip install pydotplus\n",
    "!pip install keras_ocr\n",
    "!pip install torch\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
